no---
title: "Project 1"
author: "Fadumo Hussein"
date: "2023-02-09"
output: html_document
---

## Loading packages 

```{r}
#Install Packages 
install.packages("tm")  # for text mining
install.packages("SnowballC") # for text stemming
install.packages("wordcloud") # word-cloud generator 
install.packages("RColorBrewer") # color palettes
install.packages("syuzhet") # for sentiment analysis
install.packages("ggplot2") # for plotting graphs
install.packages("readr")  # for text mining
install.packages("tidyverse")
install.packages("mice")
install.packages("forcats")
install.packages("tidytext")
# Load
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("syuzhet")
library("ggplot2")
library("readr")
library("tidyverse")
library("mice")
library("forcats")
library("tidytext")
```

## Upload data 
```{r}
book_spoilers <- read.csv("book_spoilers.csv")
book_spoilers_random  <- sample_n(book_spoilers_random,10000)
View(book_spoilers_random)
```
## Data Preparation 
```{r}

#Subset variables of interest 
reviews <- book_spoilers_random[ c("review_sentences", "rating", "has_spoiler", "book_id") ]
View(reviews)

#Remove NAs from the dataset 
md.pattern(reviews, rotate.names = TRUE)
reviews_2 <- reviews[complete.cases(reviews), ]
md.pattern(reviews_2, rotate.names = TRUE)
View(reviews_2)

#Factor the variables 

reviews_2$has_spoiler  <- fct_collapse(reviews_2$has_spoiler,
                           Yes = "True", 
                           No ="False")

table(reviews_2$has_spoiler)
View(reviews_2)
```

#New Columns 
```{r}
#We have multiple ratings for the same book, function creates a column that shows the average rating of each book

review_3 <- reviews_2 %>%
 group_by(book_id) %>%
  mutate(average_rating = mean(rating)) %>%
  as.data.frame()
review_3
View(review_3)
# This column assess whether the mean of the book ratings is higher than four (The ratings 4 and 5 are above while the rest of the variables are below ) 

review_4 <- review_3 %>% 
  left_join(review_3) %>% 
  mutate(above_average = if_else(4 <= average_rating, "Yes", "No"))

(review_4)
View(review_4)
#Factor the variables 

review_4$above_average  <- fct_collapse(review_3$above_average,
                           Yes = "Yes", 
                           No ="No")

table(review_4$above_average )
View(review_4)

```
## EDA
```{r}
#Do books with spoilers have higher ratings?  
p1 <- ggplot(review_4, aes(x=has_spoiler, y=rating, color = has_spoiler)) + 
    geom_boxplot() 
p1



```

## Cleaning up Text Data
```{r}
# Remove common words, puncutation, white, space, etc. 

review_corpus <- VCorpus(VectorSource(review_3$review_sentences))
review_corpus <- tm_map(review_corpus, content_transformer(tolower))
review_corpus <- tm_map(review_corpus, removeNumbers)
review_corpus <- tm_map(review_corpus, removePunctuation)
review_corpus <- tm_map(review_corpus, removeWords, c("the", "and", stopwords("english")))
review_corpus <- tm_map(review_corpus, stripWhitespace)
review_corpus <- tm_map(review_corpus, stemDocument)

review_corpus_1 <- data.frame(text=unlist(sapply(review_corpus, `[`, "content")), 
    stringsAsFactors=F)

view(review_corpus_1)

review_5 <- cbind(review_4,review_corpus_1)
view(review_5)

review_text <- review_5[ c("text", "has_spoiler", "book_id", "above_average") ]
View(review_text)

#Breaking down each sentence to words 
token <- review_text %>% unnest_tokens(word,text)
view(token)
class(token)


(head(get_sentiments("afinn"),10))
review_sentiment <- token %>% inner_join(get_sentiments("afinn"))
view(review_sentiment)

# summarise the sentiment value of each review
review_sentiment <- review_sentiment %>% group_by(has_spoiler, book_id, above_average) %>% 
  summarise(value = sum(value)) %>% ungroup()

(head(review_sentiment,10))
str(review_sentiment)
view(review_sentiment)


```

#One hot encode 
```{r}
#This basically makes our non numeric variables a binary 0 or 1 

review_sentiment_1h <- one_hot(as.data.table(review_sentiment),cols = "auto" ,sparsifyNAs = TRUE,naCols = FALSE,dropCols = TRUE,dropUnusedLevels = TRUE)

view(review_sentiment_1h)

```
# Prevalence 

```{r}

#let's check the prevalence 
(prevalence <- table(review_sentiment_1h$above_average)[[2]]/length(review_sentiment_1h$above_average))

table(review_sentiment_1h$above_average)


```

#train test and tune 
```{r}                                      

review_sentiment %>% 
  group_by(above_average) %>% 
  summarise(total = n()) %>% 
  mutate(proportion = (total/sum(total))*100)

review_sentiment$above_average <- as.factor(review_sentiment$above_average)


samplesize <- 0.8*nrow(review_sentiment)
index <- sample(seq_len(nrow(review_sentiment)),size = samplesize)

data_train <- review_sentiment[index,]
data_test <- review_sentiment[-index,]

```

# Model 
```{r}
logit_mod <- glm(above_average~value,data = data_train,family = binomial("logit"))

summary(logit_mod)

pred_logit <- predict(logit_mod,newdata = data_test,type = "response")
```

# Confusion Matrix 
```{r}
pred_class <- as.factor(if_else(pred_logit > 0.5, "Yes", "No"))

# confusion matrix
perf_logit1 <- confusionMatrix(data = pred_class, reference = data_test$above_average, 
    positive = "Yes")
perf_logit1
            
```

